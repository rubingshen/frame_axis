{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import gensim\n",
    "\n",
    "from functools import reduce\n",
    "from operator import or_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pio.templates.default = \"plotly_white\"\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def cos(a,b):\n",
    "    return a@b/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lf = pd.read_parquet('../data/newspaper/figaro_sents.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lf = df_lf.drop_duplicates(subset=['sent']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm = pd.read_parquet('../data/newspaper/monde_sents.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm = df_lm.drop_duplicates(subset=['sent']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_any(x, kwds):\n",
    "    return any([kw in x for kw in kwds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwds = [\"homosex\",\"LGBT\",\"lgbt\",\"mariage gay\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lf_select = df_lf[df_lf.sent.progress_apply(lambda x: contains_any(x, kwds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf_select['words'] = lf_select['sent'].progress_apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lm_select = df_lm[df_lm.sent.progress_apply(lambda x: contains_any(x, kwds))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lm_select['words'] = lm_select['sent'].progress_apply(gensim.utils.simple_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_select['newspaper'] = 'Le Monde'\n",
    "lf_select['newspaper'] = 'Le Figaro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_select = pd.concat([lm_select, lf_select],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=all_select['words'],vector_size=50, min_count=50, epochs=20, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('./models/lgbt.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = gensim.models.Word2Vec.load('./models/lgbt.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build frame axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_g = 'agression'\n",
    "w_d= 'lobby'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similar_by_word(w_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.wv.similar_by_word(w_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_d = model.wv.get_vector(w_d)\n",
    "v_g = model.wv.get_vector(w_g)\n",
    "\n",
    "frame = v_d-v_g\n",
    "list_cos = [cos(v,frame) for v in model.wv.vectors]\n",
    "dict_cos = dict(zip(model.wv.index_to_key, list_cos))\n",
    "\n",
    "def match_cos(list_words):\n",
    "    words_cos=[]\n",
    "    for w in list_words:\n",
    "        try:\n",
    "            words_cos.append(dict_cos[w])\n",
    "        except:\n",
    "            pass\n",
    "    return words_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(dict_cos).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute frame bias and intensity on sub-corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build sub-corpora (unit of analysis). Here: newspaper-year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    list_words = []\n",
    "    for wds in x:\n",
    "        if type(wds)!=list:\n",
    "            wds = wds.tolist()\n",
    "        list_words += wds\n",
    "    return list_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journ_year = all_select.groupby(['newspaper','year']).progress_apply(lambda df: flatten(df['words']))\n",
    "journ_year = journ_year.reset_index().rename({0:'words'}, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute frame bias and intensity on each sub-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "journ_year['cos'] = journ_year['words'].progress_apply(match_cos)\n",
    "journ_year['bias'] = journ_year['cos'].progress_apply(np.mean)\n",
    "journ_year['intensity'] = journ_year['cos'].progress_apply(np.var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute frame bias relative to the background corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_doc = flatten(all_select['words'])\n",
    "\n",
    "background_cos = match_cos(background_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_bias = np.mean(background_cos)\n",
    "background_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journ_year['rel_bias'] = journ_year['bias'] - background_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display bias-intensity map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journ_year['label'] = journ_year['newspaper'] + '_' + journ_year['year'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(journ_year, x='rel_bias',y='intensity', color='newspaper',text='year',\n",
    "                 labels={'rel_bias':'agression <- Microframe bias -> lobby',\n",
    "                         'intensity': 'Microframe intensity',\n",
    "                         'newspaper':'Newspaper'})\n",
    "fig.write_image('./plot/png/lgbt_bias_intensity.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Polarization trends\n",
    "\n",
    "fig = px.scatter(journ_year, x='year', y='rel_bias', color='newspaper',trendline='lowess',\n",
    "                 labels = {'newspaper':'Newspaper',\n",
    "                           'rel_bias':'Microframe bias'})\n",
    "fig.write_image('./plot/png/lgbt_bias_evolution.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_bias_per_year = journ_year.set_index('year')\n",
    "fig = px.scatter((diff_bias_per_year.loc[diff_bias_per_year['newspaper']=='Le Monde', 'bias'] - diff_bias_per_year.loc[diff_bias_per_year['newspaper']=='Le Figaro', 'bias']).apply(np.abs),\n",
    "           trendline='lowess', labels={'value':'|bias(Le Monde) - bias(Le Figaro)|'})\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.write_image('./plot/png/lgbt_polarization_evolution.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journ_year['topic'] = 'lgbt'\n",
    "journ_year[['label','newspaper','year','rel_bias','topic']].to_csv('./csv/bias_lgbt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bias and intensity per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_select['cos'] = all_select['words'].progress_apply(match_cos)\n",
    "all_select['bias'] = all_select['cos'].progress_apply(np.mean)\n",
    "all_select['intensity'] = all_select['cos'].progress_apply(np.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_select['sent_display'] = all_select['sent'].progress_apply(lambda x: ' '.join([a for b in [x.split(' ')[i:i+20]+['<br>'] for i in range(0,len(x.split(' ')), 20)] for a in b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1_label = 'Le Monde_2002'\n",
    "doc2_label = 'Le Figaro_2012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_select['label'] = (all_select['newspaper'] + '_' + all_select['year'].apply(str)).apply(lambda x: x if x in [doc1_label, doc2_label] else 'autre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(all_select,\n",
    "                 x='bias',y='intensity',\n",
    "                 color='label',\n",
    "                 hover_data=['sent_display','newspaper','date','author'],\n",
    "                 labels={'bias':'agression <- Microframe bias -> lobby',\n",
    "                         'intensity': 'Microframe intensity'})\n",
    "fig.update_traces(marker=dict(size=3,opacity=1))\n",
    "\n",
    "fig.write_html('./plot/html/lgbt_bias_per_sentence.html')\n",
    "fig.write_image('./plot/png/lgbt_bias_per_sentence.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
